{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Using Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from functools import lru_cache\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import recall_score\n",
    "import optuna\n",
    "from utility_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "products_path = \"./data/products_train.csv\"\n",
    "train_sessions_path = \"./data/sessions_train.csv\"\n",
    "test_sessions_path = \"./data/sessions_test_task1.csv\"\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_product_data():\n",
    "    return pd.read_csv(products_path)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_train_data():\n",
    "    train_df = pd.read_csv(train_sessions_path)\n",
    "    train_df[\"prev_items\"] = (\n",
    "        train_df[\"prev_items\"].str.strip(\n",
    "            \"[']\").str.replace(\"\\n\", \"\").str.split(\"' '\")\n",
    "    )\n",
    "    train_df[\"all_items\"] = train_df.apply(\n",
    "        lambda row: list(row[\"prev_items\"]) + [row[\"next_item\"]], axis=1\n",
    "    )\n",
    "    return train_df\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_test_data():\n",
    "    test_df = pd.read_csv(test_sessions_path)\n",
    "    test_df[\"prev_items\"] = (\n",
    "        test_df[\"prev_items\"].str.strip(\n",
    "            \"[']\").str.replace(\"\\n\", \"\").str.split(\"' '\")\n",
    "    )\n",
    "    test_df[\"all_items\"] = test_df.apply(\n",
    "        lambda row: list(row[\"prev_items\"]) + [row[\"next_item\"]], axis=1\n",
    "    )\n",
    "    return test_df\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_seperated_train_data():\n",
    "    train_df = read_train_data()\n",
    "    # seperate train datasets for each locale\n",
    "    train_whole_de_df = train_df[train_df[\"locale\"] == \"DE\"]\n",
    "    train_whole_uk_df = train_df[train_df[\"locale\"] == \"UK\"]\n",
    "    train_whole_jp_df = train_df[train_df[\"locale\"] == \"JP\"]\n",
    "    # remove locale columns\n",
    "    train_whole_de_df = train_whole_de_df.drop(columns=\"locale\")\n",
    "    train_whole_uk_df = train_whole_uk_df.drop(columns=\"locale\")\n",
    "    train_whole_jp_df = train_whole_jp_df.drop(columns=\"locale\")\n",
    "    # create seperate train and validation sets\n",
    "    # this enables testing the models before making a submition to the competition\n",
    "    train_de_df, val_de_df = train_test_split(train_whole_de_df, test_size=0.2)\n",
    "    train_uk_df, val_uk_df = train_test_split(train_whole_uk_df, test_size=0.2)\n",
    "    train_jp_df, val_jp_df = train_test_split(train_whole_jp_df, test_size=0.2)\n",
    "    return (\n",
    "        (train_de_df, val_de_df),\n",
    "        (train_uk_df, val_uk_df),\n",
    "        (train_jp_df, val_jp_df),\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_sepereated_item_user_combinations():\n",
    "    user_items_dfs = []\n",
    "    for df_tuple in read_seperated_train_data():\n",
    "        train_df = df_tuple[0]\n",
    "        val_df = df_tuple[1]\n",
    "        train_users_items = train_df[\"all_items\"].explode()\n",
    "        val_users_items = val_df[\"all_items\"].explode()\n",
    "        train_users_items = pd.DataFrame(\n",
    "            {\"user\": train_users_items.index, \"item\": train_users_items}\n",
    "        )\n",
    "        val_users_items = pd.DataFrame(\n",
    "            {\"user\": val_users_items.index, \"item\": val_users_items}\n",
    "        )\n",
    "        # drop duplicates -> binary values only\n",
    "        train_users_items = train_users_items.drop_duplicates()\n",
    "        val_users_items = val_users_items.drop_duplicates()\n",
    "        # reset index\n",
    "        train_users_items = train_users_items.reset_index()\n",
    "        val_users_items = val_users_items.reset_index()\n",
    "        user_items_dfs.append((train_users_items, val_users_items))\n",
    "    return user_items_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (train_de_df, val_de_df),\n",
    "    (train_uk_df, val_uk_df),\n",
    "    (train_jp_df, val_jp_df),\n",
    ") = read_seperated_train_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components,\n",
    "        max_iter=200,\n",
    "        init=None,\n",
    "        solver=\"cd\",\n",
    "        beta_loss=\"frobenius\",\n",
    "        alpha_W=0.0,\n",
    "        alpha_H=\"same\",\n",
    "        l1_ratio=0.0,\n",
    "        random_state=0,\n",
    "    ):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.init = init\n",
    "        self.solver = solver\n",
    "        self.beta_loss = beta_loss\n",
    "        self.alpha_W = alpha_W\n",
    "        self.alpha_H = alpha_H\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.random_state = random_state\n",
    "        self.user_item_matrix_df = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # build a sparse dataframe to store sessions data\n",
    "        te = TransactionEncoder()\n",
    "        user_item_matrix = te.fit(dataset).transform(dataset, sparse=True)\n",
    "        self.user_item_matrix_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "            user_item_matrix, columns=te.columns_, index=dataset.index\n",
    "        )\n",
    "        # perform non-negative matrix factorization and store user matrix (W) and item matrix (H) in this object\n",
    "        model = NMF(\n",
    "            n_components=self.n_components,\n",
    "            max_iter=self.max_iter,\n",
    "            init=self.init,\n",
    "            solver=self.solver,\n",
    "            beta_loss=self.beta_loss,\n",
    "            alpha_W=self.alpha_W,\n",
    "            alpha_H=self.alpha_H,\n",
    "            l1_ratio=self.l1_ratio,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        self.W = pd.DataFrame(\n",
    "            model.fit_transform(self.user_item_matrix_df),\n",
    "            index=self.user_item_matrix_df.index,\n",
    "        )\n",
    "        self.H = pd.DataFrame(\n",
    "            model.components_, columns=self.user_item_matrix_df.columns\n",
    "        )\n",
    "\n",
    "    def get_recommendations(self, users=None, remove_already_bought_items=True, n=100):\n",
    "        if type(users) != type(None):\n",
    "            W_selection = self.W.loc[users]\n",
    "            user_item_matrix_df_selection = self.user_item_matrix_df.loc[users]\n",
    "        else:\n",
    "            W_selection = self.W\n",
    "            user_item_matrix_df_selection = self.user_item_matrix_df\n",
    "        n_users = W_selection.shape[0]\n",
    "        all_recom_items = []\n",
    "        # iterate over user matrix in batches of 100 users -> memory\n",
    "        for i in range(n_users // 100 + 1):\n",
    "            from_idx = 100 * i\n",
    "            to_idx = 100 * (i + 1) if 100 * (i + 1) <= n_users else n_users\n",
    "            # reconstructed scores\n",
    "            scores = np.dot(W_selection.iloc[from_idx:to_idx], self.H)\n",
    "            true_scores = user_item_matrix_df_selection.iloc[from_idx:to_idx].values\n",
    "            # if defined manually set scores to 0 for items that are already in the original set\n",
    "            if remove_already_bought_items:\n",
    "                scores[true_scores == 1] = 0\n",
    "            # sort index by score, best item first...\n",
    "            idx_best = np.flip(np.argsort(scores))[:, -n:]\n",
    "            # ...and use index to retrieve item ids\n",
    "            recom_items = user_item_matrix_df_selection.columns.values[idx_best]\n",
    "            all_recom_items.append(recom_items)\n",
    "        all_recom_items = np.concatenate(all_recom_items)\n",
    "        return all_recom_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 15:49:14,931]\u001b[0m A new study created in memory with name: no-name-d7c48af6-057a-49c0-953e-e878b8e0d183\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 15:54:36,245]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_components': 24, 'init': 'random', 'alpha_W_and_H': 8.337337193969478, 'l1_ratio': 0.5540777215449285}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:02:05,046]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_components': 63, 'init': 'nndsvda', 'alpha_W_and_H': 4.647421534933819, 'l1_ratio': 0.14685523755644592}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:08:14,411]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'n_components': 34, 'init': 'nndsvd', 'alpha_W_and_H': 7.4264728854301705, 'l1_ratio': 0.08559395773748546}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:13:54,579]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'n_components': 34, 'init': 'random', 'alpha_W_and_H': 8.648934929015612, 'l1_ratio': 0.891442175595899}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:20:05,902]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_components': 32, 'init': 'nndsvd', 'alpha_W_and_H': 2.6478631639436037, 'l1_ratio': 0.6938438191952694}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:25:09,789]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_components': 6, 'init': 'nndsvda', 'alpha_W_and_H': 5.949113290246811, 'l1_ratio': 0.9957246486366853}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n",
      "\u001b[32m[I 2023-04-27 16:30:49,875]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_components': 29, 'init': 'nndsvd', 'alpha_W_and_H': 1.7992581371503735, 'l1_ratio': 0.1322807643931705}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "/home/felix/anaconda3/envs/dm2_project/lib/python3.10/site-packages/sklearn/utils/validation.py:810: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
      "  array = array.astype(new_dtype)\n"
     ]
    }
   ],
   "source": [
    "# concatenate all_items column of train df with prev_items column of validation df\n",
    "de_sessions = pd.concat([train_de_df[\"all_items\"], val_de_df[\"prev_items\"]])\n",
    "# sample 500 users from the validation set to test the results\n",
    "val_de_users_subset = np.random.choice(val_de_df.index.values, 500, replace=False)\n",
    "val_de_subset_next_items = val_de_df.loc[val_de_users_subset, \"next_item\"]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # build and train model on this data\n",
    "    mf_model_de = MatrixFactorizationModel(\n",
    "        n_components=trial.suggest_int(\"n_components\", 5, 100),\n",
    "        init=trial.suggest_categorical(\"init\", [\"random\", \"nndsvd\", \"nndsvda\"]),\n",
    "        # beta_loss=trial.suggest_categorical(\"beta_loss\", [\"frobenius\", \"kullback-leibler\"]),\n",
    "        alpha_W=trial.suggest_float(\"alpha_W_and_H\", 0, 10),\n",
    "        l1_ratio=trial.suggest_float(\"l1_ratio\", 0, 1),\n",
    "        max_iter=500,\n",
    "    )\n",
    "    mf_model_de.fit(de_sessions)\n",
    "\n",
    "    # make recommendations for 500 users from the validation set\n",
    "    val_de_subset_recoms = mf_model_de.get_recommendations(users=val_de_users_subset)\n",
    "\n",
    "    # calculate mrr\n",
    "    mrr_val_de_subset, rr_list = mean_reciprocal_rank(\n",
    "        val_de_subset_recoms, val_de_subset_next_items\n",
    "    )\n",
    "\n",
    "    return mrr_val_de_subset\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in study.trials:\n",
    "    hyperparams = trial.params\n",
    "    result = trial.value\n",
    "    print(f\"Hyperparameters: {hyperparams}, Result: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm2_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
